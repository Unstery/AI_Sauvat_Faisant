{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI - TP1_2\n",
    "\n",
    "Bastien SAUVAT et Bastien FAISANT\n",
    "\n",
    "# Exercise 3 : Text classification on the Ohsumed dataset\n",
    "\n",
    "*Objective : The goal of this exercise is to realize a text classifier using deep neural networks. Your task\n",
    "is to construct a classifier, using the available training set, and evaluate it using the test set. The classifier\n",
    "should predict the category for the articles.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, Dropout, GlobalAveragePooling1D, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "from tensorflow.keras import regularizers\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(path: str):\n",
    "    data = list(os.walk(path))[1:]\n",
    "    files = []\n",
    "    for d in data:\n",
    "        folder_name = d[0]\n",
    "        for file in d[2]:\n",
    "            files.append((folder_name.split('/')[-1], os.path.join(folder_name, file)))\n",
    "\n",
    "    d = defaultdict(int)\n",
    "    texts = defaultdict(list)\n",
    "    for (cate, file) in files:\n",
    "        with open(file, 'r') as outfile:\n",
    "            text = outfile.read()\n",
    "            texts[cate].append(text)\n",
    "            words = text_to_word_sequence(text)\n",
    "            for word in words:\n",
    "                d[word] += 1\n",
    "    words = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "    return (texts, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_texts, training_words = get_info(\"./data/ohsumed-first-20000-docs/training/\")\n",
    "test_texts, test_words = get_info(\"./data/ohsumed-first-20000-docs/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(dataset: defaultdict[any, list]):\n",
    "    classes = []\n",
    "    texts = []\n",
    "    for classe, liste_texts in dataset.items():\n",
    "        for text in liste_texts:\n",
    "            texts.append(text)\n",
    "            classes.append(classe)\n",
    "\n",
    "    df = pd.DataFrame({'Classes': classes, 'Texts': texts})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_df(training_texts)\n",
    "test_set = get_df(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C01</td>\n",
       "      <td>Augmentation mentoplasty using Mersilene mesh....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C01</td>\n",
       "      <td>Multiple intracranial mucoceles associated wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C01</td>\n",
       "      <td>Replacement of an aortic valve cusp after neon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C01</td>\n",
       "      <td>The value of indium 111 leukocyte scanning in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C01</td>\n",
       "      <td>Febrile infants less than eight weeks old. Pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classes                                              Texts\n",
       "0     C01  Augmentation mentoplasty using Mersilene mesh....\n",
       "1     C01  Multiple intracranial mucoceles associated wit...\n",
       "2     C01  Replacement of an aortic valve cusp after neon...\n",
       "3     C01  The value of indium 111 leukocyte scanning in ...\n",
       "4     C01  Febrile infants less than eight weeks old. Pre..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10433 entries, 0 to 10432\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Classes  10433 non-null  object\n",
      " 1   Texts    10433 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 163.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10433</td>\n",
       "      <td>10433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>23</td>\n",
       "      <td>6286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>C23</td>\n",
       "      <td>Magnetic resonance imaging of radiation optic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1799</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classes                                              Texts\n",
       "count    10433                                              10433\n",
       "unique      23                                               6286\n",
       "top        C23  Magnetic resonance imaging of radiation optic ...\n",
       "freq      1799                                                  6"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.info()\n",
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12733 entries, 0 to 12732\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Classes  12733 non-null  object\n",
      " 1   Texts    12733 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 199.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12733</td>\n",
       "      <td>12733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>23</td>\n",
       "      <td>7643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>C23</td>\n",
       "      <td>The butterfly rash and the malar flush. What d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2153</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classes                                              Texts\n",
       "count    12733                                              12733\n",
       "unique      23                                               7643\n",
       "top        C23  The butterfly rash and the malar flush. What d...\n",
       "freq      2153                                                  7"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.info()\n",
    "test_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes_to_integers(classes):\n",
    "    unique_classes = classes.unique()\n",
    "    class_mapping = {cls: int(cls[1:]) for cls in unique_classes}\n",
    "    return classes.replace(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(texts: defaultdict[any, list]):\n",
    "    df = get_df(texts)\n",
    "\n",
    "    x_data = df['Texts']\n",
    "    y_data = df['Classes']\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "\n",
    "    # Replace class name by their number\n",
    "    y_data = convert_classes_to_integers(y_data)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset(training_texts)\n",
    "x_test, y_test = load_dataset(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[ 5193 14808    77 ...     0     0     0]\n",
      " [  211  1075  8608 ...     0     0     0]\n",
      " [  553   218   365 ...     0     0     0]\n",
      " ...\n",
      " [ 4991  4992  2104 ...     0     0     0]\n",
      " [   20  5924   763 ...  1854   216  2528]\n",
      " [   86   422   553 ...     0     0     0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[ 3705  2377  1165 ...     0     0     0]\n",
      " [  784 12827  1953 ...  1619  1710  2150]\n",
      " [  699    96  2161 ...   300   400   160]\n",
      " ...\n",
      " [  479  1571  4739 ...   194    77 10236]\n",
      " [  184   163   279 ...   346   184   279]\n",
      " [  835  7339  2064 ...     0     0     0]] \n",
      "\n",
      "Maximum review length:  112\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 112, 32)           905888    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 112, 32)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 32)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 905,921\n",
      "Trainable params: 905,921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "# model.add(LSTM(LSTM_OUT))\n",
    "# #todo : modify activation and/or optimizer to improve accuracy\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  Embedding(total_words, EMBED_DIM, input_length = max_length),\n",
    "  Dropout(0.2),\n",
    "  GlobalAveragePooling1D(),\n",
    "  Dropout(0.2),\n",
    "  Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - ETA: 0s - loss: 29.4238 - accuracy: 0.0000e+00\n",
      "Epoch 1: accuracy improved from -inf to 0.00000, saving model to models\\LSTM.h5\n",
      "82/82 [==============================] - 3s 12ms/step - loss: 29.4238 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "79/82 [===========================>..] - ETA: 0s - loss: 10.9485 - accuracy: 0.0017   \n",
      "Epoch 2: accuracy improved from 0.00000 to 0.00220, saving model to models\\LSTM.h5\n",
      "82/82 [==============================] - 1s 13ms/step - loss: 10.7391 - accuracy: 0.0022\n",
      "Epoch 3/5\n",
      "78/82 [===========================>..] - ETA: 0s - loss: -17.4091 - accuracy: 0.0307\n",
      "Epoch 3: accuracy improved from 0.00220 to 0.03077, saving model to models\\LSTM.h5\n",
      "82/82 [==============================] - 1s 14ms/step - loss: -19.8515 - accuracy: 0.0308\n",
      "Epoch 4/5\n",
      "80/82 [============================>.] - ETA: 0s - loss: -164.0307 - accuracy: 0.0404\n",
      "Epoch 4: accuracy improved from 0.03077 to 0.04054, saving model to models\\LSTM.h5\n",
      "82/82 [==============================] - 1s 12ms/step - loss: -164.3622 - accuracy: 0.0405\n",
      "Epoch 5/5\n",
      "80/82 [============================>.] - ETA: 0s - loss: -184.8208 - accuracy: 0.0400\n",
      "Epoch 5: accuracy did not improve from 0.04054\n",
      "82/82 [==============================] - 1s 14ms/step - loss: -184.8834 - accuracy: 0.0405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aa1e24c970>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 5s 27ms/step\n",
      "Correct Prediction: 506\n",
      "Wrong Prediction: 12227\n",
      "Accuracy: 3.973926019005733\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, batch_size = 128)\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true += 1\n",
    "\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
